import os
from typing import List, Dict
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from dotenv import load_dotenv
from supabase import create_client, Client

# LangChain Imports
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

#pythainlp
from pythainlp.util import normalize          # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏™‡∏£‡∏∞/‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå
from pythainlp.tokenize import word_tokenize  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏à‡∏≤‡∏Å .env (‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏ï‡πà‡∏≤‡∏á‡πÜ)
load_dotenv()

# 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Supabase (‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# 3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ AI (Typhoon API)
# ‡πÉ‡∏ä‡πâ ChatOpenAI ‡πÅ‡∏ï‡πà‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Server ‡∏Ç‡∏≠‡∏á Typhoon
llm = ChatOpenAI(
    base_url=os.getenv("TYPHOON_BASE_URL"), # https://api.opentyphoon.ai/v1
    api_key=os.getenv("TYPHOON_API_KEY"),
    model="typhoon-v2.5-30b-a3b-instruct",      # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏á‡∏™‡∏∏‡∏î
    temperature=0.3,                         # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡∏ï‡πà‡∏≥‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢
    max_tokens=4096                          # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ AI ‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß‡πÜ ‡πÑ‡∏î‡πâ ‡πÑ‡∏°‡πà error
)

# 4. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Embedding (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
# ‡πÉ‡∏ä‡πâ BGE-M3 ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏Å‡πà‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")

# 5. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏≠‡∏õ FastAPI
app = FastAPI()

# --- Data Models (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö-‡∏™‡πà‡∏á) ---

class ChatRequest(BaseModel):
    question: str
    history: List[Dict[str, str]] = []  # ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ (Context Awareness)

class ChatResponse(BaseModel):
    answer: str
    sources: List[str]                  # ‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ (Citation)

# --- Helper Functions (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô) ---

def preprocess_thai_text(text: str) -> str:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Text Preprocessing) ‡∏ï‡∏≤‡∏° Proposal
    1. Normalize: ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏£‡∏∞‡∏•‡∏≠‡∏¢ ‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡∏ã‡πâ‡∏≠‡∏ô
    2. Tokenize: ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Embedding Model ‡∏à‡∏±‡∏ö‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
    """
    # 1. ‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡∏∞‡∏≠‡∏≥ ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ú‡∏¥‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö)
    clean_text = normalize(text)
    
    # 2. ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á (‡πÄ‡∏ä‡πà‡∏ô "‡∏•‡∏≤‡∏Å‡∏¥‡∏à‡πÑ‡∏î‡πâ‡∏Å‡∏µ‡πà‡∏ß‡∏±‡∏ô" -> "‡∏•‡∏≤‡∏Å‡∏¥‡∏à ‡πÑ‡∏î‡πâ ‡∏Å‡∏µ‡πà ‡∏ß‡∏±‡∏ô")
    # ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3 ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ñ‡∏≥‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
    words = word_tokenize(clean_text, engine="newmm", keep_whitespace=False)
    
    return " ".join(words)

def retrieve_data(question: str):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Supabase"""
    print(f"   üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: {question}")
    
    # 1. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô Vector
    query_vector = embeddings.embed_query(question)
    
    # 2. ‡∏¢‡∏¥‡∏á‡πÑ‡∏õ‡∏ñ‡∏≤‡∏° Supabase (‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô match_sections_v2 ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô SQL)
    response = supabase.rpc(
        "match_sections_v2",
        {
            "query_embedding": query_vector,
            "match_threshold": 0.5, # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ 50%
            "match_count": 5        # ‡πÄ‡∏≠‡∏≤‡∏°‡∏≤ 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
        }
    ).execute()
    
    return response.data

def rewrite_question(question: str, history: List[Dict[str, str]]) -> str:
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Context Awareness: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÜ ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡∏î‡∏π‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥"""
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏Å‡πà‡∏≤ ‡∏Å‡πá‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏•‡∏¢
    if not history:
        return question
    
    print("   üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà (Query Rewriting)...")
    
    # ‡πÅ‡∏õ‡∏•‡∏á History List ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° String
    history_text = ""
    for msg in history[-4:]: # ‡∏î‡∏π‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Ñ‡πà 2-3 ‡∏Ñ‡∏π‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏û‡∏≠ (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Token)
        role = "User" if msg['role'] == 'user' else "AI"
        history_text += f"{role}: {msg['content']}\n"
    
    # Prompt ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà (Standalone Question)
    rewrite_template = """
    ‡∏à‡∏≤‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
    {chat_history}
    
    ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: "{question}"
    
    ‡∏à‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà" ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á (Standalone Question) 
    ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    (‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô‡∏ô‡∏≥ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏û‡∏π‡∏î)
    
    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà:
    """
    
    try:
        prompt = PromptTemplate(template=rewrite_template, input_variables=["chat_history", "question"])
        chain = prompt | llm | StrOutputParser()
        
        # ‡∏™‡∏±‡πà‡∏á AI ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        new_question = chain.invoke({"chat_history": history_text, "question": question})
        
        print(f"   ‚ú® ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ: {new_question}")
        return new_question.strip()
        
    except Exception as e:
        print(f"   ‚ùå Error rewriting: {e}")
        return question # ‡∏ñ‡πâ‡∏≤ error ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô

# --- Main API Endpoint ---

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    try:
        # --- [NEW] Step 0: Text Preprocessing (PyThaiNLP) ---
        # ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏° Proposal ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ [cite: 45, 201]
        processed_question = preprocess_thai_text(request.question)
        print(f"   üßπ Cleaned Input: {processed_question}") # ‡πÄ‡∏ä‡πá‡∏Ñ Log ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏´‡∏°
        
        # Step 1: Context Awareness (Query Rewriting)
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        search_query = rewrite_question(request.question, request.history)
        
        # Step 2: Retrieval (‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà)
        retrieved_docs = retrieve_data(search_query)
        
        # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢
        if not retrieved_docs:
            return ChatResponse(answer="‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", sources=[])

        # Step 3: Prepare Context (‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏™‡πà Prompt)
        # --- Step 3: Prepare Context (‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏™‡πà Prompt) ---
        context_text = ""
        sources_set = set() # ‡πÉ‡∏ä‡πâ set ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥
        
        for doc in retrieved_docs:
            sec_num = doc.get('section_number', '?')
            text = doc.get('text_original', '')
            # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ö (‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏≠‡πà‡∏≤‡∏ô)
            context_text += f"- ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ {sec_num}: {text}\n\n"
            # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏•‡∏Ç‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏•‡∏á set (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ã‡πâ‡∏≥)
            sources_set.add(f"‡∏°‡∏≤‡∏ï‡∏£‡∏≤ {sec_num}")
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô list ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° (‡πÄ‡∏ä‡πà‡∏ô ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 9, 76, 118)
        # ‡πÉ‡∏ä‡πâ lambda ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏á (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö string ‡πÄ‡∏ä‡πà‡∏ô 1, 10, 2)
        try:
            sources_list = sorted(list(sources_set), key=lambda x: int(x.split()[-1]) if x.split()[-1].isdigit() else 9999)
        except:
            sources_list = sorted(list(sources_set)) # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡πá‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏õ‡∏Å‡∏ï‡∏¥

        # Step 4: Generation (‡πÉ‡∏´‡πâ AI ‡∏ï‡∏≠‡∏ö)
        template = """
        ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡πÑ‡∏ó‡∏¢ (Thai Labour Law Expert)
        ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏Å‡πà‡∏•‡∏π‡∏Å‡∏à‡πâ‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
        
        ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:
        {context}
        
        ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}
        
        ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
        1. ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢" ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        2. ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö
        3. ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏•‡∏Ç‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡πÄ‡∏™‡∏°‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢
        4. ‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        
        ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
        """
        
        prompt = PromptTemplate(template=template, input_variables=["context", "question"])
        chain = prompt | llm | StrOutputParser()
        
        # ‡∏™‡πà‡∏á search_query (‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÅ‡∏•‡πâ‡∏ß) + context ‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI
        ai_answer = chain.invoke({"context": context_text, "question": search_query})
        
        # Step 5: Return Result (‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö + ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ)
        return ChatResponse(answer=ai_answer, sources=sources_list)

    except Exception as e:
        print(f"Server Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô: python -m uvicorn api:app --reload